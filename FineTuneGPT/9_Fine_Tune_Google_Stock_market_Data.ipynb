{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbXtKqb7VaLDUZso6BCAwZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**To fine-tune a GPT-3 Babbage-02 model**\n","\n","for stock price prediction, we'll walk through the process step-by-step, from preparing the data to fine-tuning the model. Here's how you can do it conceptually, along with some code examples.\n","\n","**Step 1: Load and Explore the Data**\n","\n","First, let's load the provided stock data and examine its structure."],"metadata":{"id":"EeaZQ4G0AEZb"}},{"cell_type":"code","source":["!pip install --upgrade openai --quiet\n","\n","from google.colab import userdata\n","OPEN_AI_KEY=userdata.get('opeaikey4o')\n","\n","from openai import OpenAI\n","import matplotlib.pyplot as plt\n","import time\n","\n","\n","client = OpenAI(api_key=OPEN_AI_KEY)"],"metadata":{"id":"3axJLLPbAaRq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the CSV file\n","file_path = 'GOOGLE_stock.csv'\n","data = pd.read_csv(file_path)\n","\n","# Display the first few rows of the data\n","print(data.head())\n"],"metadata":{"id":"genpuLY0AXiL","executionInfo":{"status":"ok","timestamp":1724502384231,"user_tz":-60,"elapsed":405,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["len(data)"],"metadata":{"id":"6tb_qXi9cpTk","executionInfo":{"status":"ok","timestamp":1724499938622,"user_tz":-60,"elapsed":302,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_data_df=data[:int(len(data)*0.8)]\n","validation_data_df=data[int(len(data)*0.8):]"],"metadata":{"id":"tW3VmbGecsh6","executionInfo":{"status":"ok","timestamp":1724501734729,"user_tz":-60,"elapsed":263,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["len(training_data_df)"],"metadata":{"id":"5kbg4VB3dNxQ","executionInfo":{"status":"ok","timestamp":1724499945105,"user_tz":-60,"elapsed":956,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(validation_data_df)"],"metadata":{"id":"a_RXIq6PdPGq","executionInfo":{"status":"ok","timestamp":1724499949454,"user_tz":-60,"elapsed":290,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_data_df.head()"],"metadata":{"id":"pbOmmthedU0J","executionInfo":{"status":"ok","timestamp":1724502378979,"user_tz":-60,"elapsed":310,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["validation_data_df.head()"],"metadata":{"id":"iMEa_C6lhlAk","executionInfo":{"status":"ok","timestamp":1724499960157,"user_tz":-60,"elapsed":284,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This code will load the CSV file and display the first few rows so we can understand what the data looks like. Typically, the columns might include Date, Open, High, Low, Close, Volume, etc.\n","\n","**Step 2: Preprocess the Data**\n","\n","We need to preprocess the data, converting it into a format that GPT  can understand. We'll create a textual representation of the data, since GPT models are designed to handle text.\n","\n","**Scaling the Data**\n","\n","We'll scale the numerical features to make the training process smoother and ensure the model's outputs are within a reasonable range."],"metadata":{"id":"soNb8Nf0Ag4B"}},{"cell_type":"markdown","source":["# Preprocessing data"],"metadata":{"id":"kFtm4_ZoeV46"}},{"cell_type":"code","source":["def create_text_dataset(data, look_back=5):\n","    X, y = [], []\n","    for i in range(len(data) - look_back):\n","        input_sequence = data.iloc[i:i + look_back]  # Use iloc for integer-based indexing\n","        target = data.iloc[i + look_back]['Close']  # Access 'Close' column by name\n","        input_text = f\"Open: {input_sequence.iloc[-1]['Open']}, High: {input_sequence.iloc[-1]['High']}, Low: {input_sequence.iloc[-1]['Low']}, Volume: {input_sequence.iloc[-1]['Volume']}\"\n","        print(input_text)\n","        output_text = f\" Close: {target}\"\n","        X.append(input_text)\n","        y.append(output_text)\n","    return X, y\n","\n","look_back = 2  # Number of previous days to consider for prediction\n","X_text, y_text = create_text_dataset(training_data_df, look_back)  # Assuming 'training_data_df' is defined\n","\n","# Combine input and output text for fine-tuning\n","train_texts = [input_text + output_text for input_text, output_text in zip(X_text, y_text)]"],"metadata":{"id":"YIwdMtDnDKeI","executionInfo":{"status":"ok","timestamp":1724501936275,"user_tz":-60,"elapsed":269,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Validation data"],"metadata":{"id":"mRCwlb9AeRQP"}},{"cell_type":"code","source":["def create_text_dataset(data, look_back=5):\n","    X, y = [], []\n","    for i in range(len(data) - look_back):\n","        input_sequence = data.iloc[i:i + look_back]  # Use iloc for integer-based indexing\n","        target = data.iloc[i + look_back]['Close']  # Access 'Close' column by name\n","        input_text = f\"Open: {input_sequence.iloc[-1]['Open']}, High: {input_sequence.iloc[-1]['High']}, Low: {input_sequence.iloc[-1]['Low']}, Volume: {input_sequence.iloc[-1]['Volume']}\"\n","        output_text = f\" Close: {target}\"\n","        X.append(input_text)\n","        y.append(output_text)\n","    return X, y\n","\n","look_back = 5  # Number of previous days to consider for prediction\n","X_text, y_text = create_text_dataset(validation_data_df, look_back)  # Assuming 'training_data_df' is defined\n","\n","# Combine input and output text for fine-tuning\n","Validation_texts = [input_text + output_text for input_text, output_text in zip(X_text, y_text)]"],"metadata":{"id":"GXGRzpljbGx-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prepare the data in the format required for fine-tuning\n"],"metadata":{"id":"kbtAHH_ugWFL"}},{"cell_type":"code","source":["\n","training_data = [{\"prompt\": x.split(\" Close:\")[0], \"completion\": x.split(\" Close:\")[1]} for x in train_texts]\n"],"metadata":{"id":"zLXZJmAQgT9E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","validation_data = [{\"prompt\": x.split(\" Close:\")[0], \"completion\": x.split(\" Close:\")[1]} for x in Validation_texts]\n"],"metadata":{"id":"S6fu_2eugXYg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### We then need to save our data as .jsonl files, with each line being one training example conversation.\n","\n"],"metadata":{"id":"FbVjf_bde_gF"}},{"cell_type":"code","source":["import json\n","import openai\n","import os\n","import pandas as pd\n","from pprint import pprint\n","import time\n","import matplotlib.pyplot as plt"],"metadata":{"id":"K6WHXjiKfGds"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def write_jsonl(data_list:list,filename:str):\n","  with open(filename,\"w\") as out:\n","    for data in data_list:\n","      jout=json.dumps(data)+\"\\n\"\n","      out.write(jout)\n","\n"],"metadata":{"id":"HcEvJiznfBFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_file_name=\"google_stock_training.jsonl\"\n","write_jsonl(training_data,training_file_name)\n","\n","validation_file_name=\"google_stock_validation.jsonl\"\n","write_jsonl(validation_data,validation_file_name)"],"metadata":{"id":"rbcLuSwkfC2E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!head -n 5 google_stock_training.jsonl"],"metadata":{"id":"lkuhr_aRfm5G","executionInfo":{"status":"ok","timestamp":1724499986213,"user_tz":-60,"elapsed":277,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!head -n 5 google_stock_validation.jsonl"],"metadata":{"id":"Gh4mZyqDrQxX","executionInfo":{"status":"ok","timestamp":1724499991081,"user_tz":-60,"elapsed":273,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!openai tools fine_tunes.prepare_data -f google_stock_training.jsonl  -q"],"metadata":{"id":"wWs-QNjTrUtL","executionInfo":{"status":"ok","timestamp":1724499995718,"user_tz":-60,"elapsed":260,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!openai tools fine_tunes.prepare_data -f google_stock_validation.jsonl  -q"],"metadata":{"id":"PI2jIrosrgv1","executionInfo":{"status":"ok","timestamp":1724500015592,"user_tz":-60,"elapsed":263,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_file=client.files.create(file=open(\"google_stock_training_prepared.jsonl\", \"rb\"),purpose='fine-tune')\n","valid_file=client.files.create(file=open(\"google_stock_validation_prepared.jsonl\", \"rb\"),purpose='fine-tune')\n"],"metadata":{"id":"4UvdwIoartUb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Upload files\n","You can now upload the files to our Files endpoint to be used by the fine-tuned model.\n","\n"],"metadata":{"id":"18-mCLsIfwX7"}},{"cell_type":"markdown","source":["**Step 3: Fine-Tune the GPT 3 Babbage-02 Model**\n","\n","Fine-tuning GPT-3 Babbage generally requires access to OpenAI's fine-tuning API. Here's a conceptual approach to how this would be done:\n","\n","Prepare the Dataset: Ensure your data is ready in the format required by GPT-4 3 Babbage.\n","\n","Use OpenAI's API for Fine-Tuning: Fine-tune the model using OpenAI's API.\n","Here’s how you might structure the process conceptually:\n","\n","**Dataset Preparation**\n","\n","Prepare the dataset for fine-tuning by structuring the inputs and outputs into prompts and completions."],"metadata":{"id":"ykOLbNYzDUyS"}},{"cell_type":"code","source":["fine_tuning_job=client.fine_tuning.jobs.create(training_file=train_file.id,validation_file=valid_file.id,model=\"babbage-002\")\n","print(fine_tuning_job)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ab9amPQmsIqN","executionInfo":{"status":"ok","timestamp":1724350989544,"user_tz":-60,"elapsed":1904,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}},"outputId":"b9f64914-c8e8-4144-ac61-6c428ce4579c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FineTuningJob(id='ftjob-oSloWqk2PdQcQkxlD91ShgcC', created_at=1724350987, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='babbage-002', object='fine_tuning.job', organization_id='org-PRq3tYU2rFVBkygKcRdWRjwB', result_files=[], seed=1157125374, status='validating_files', trained_tokens=None, training_file='file-ySLbv8wO8ZuPjATSBzA80aXN', validation_file='file-zH1yjtOZuOD58pgPk8qprRaW', estimated_finish=None, integrations=[], user_provided_suffix=None)\n"]}]},{"cell_type":"code","source":["retrieved_jobs=client.fine_tuning.jobs.retrieve(fine_tuning_job.id)\n","status=retrieved_jobs.status\n","print(status)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vfvqXnfjsI0B","executionInfo":{"status":"ok","timestamp":1724351001225,"user_tz":-60,"elapsed":618,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}},"outputId":"d34a7581-c52f-4bf5-dfcd-6e0ae6970a9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["validating_files\n"]}]},{"cell_type":"code","source":["fine_tuning_job_id=fine_tuning_job.id"],"metadata":{"id":"LPPAiiWkvFxv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fine_tuning_job_id='ftjob-oSloWqk2PdQcQkxlD91ShgcC'"],"metadata":{"id":"qTXjVfGhVVB0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["while True:\n","  time.sleep(5)\n","  retrieved_jobs=client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n","  status=retrieved_jobs.status\n","  print(status)\n","  if(status=='succeeded'):\n","    break\n","  if(status=='failed'):\n","    break"],"metadata":{"id":"j-0REM0ysT87","executionInfo":{"status":"ok","timestamp":1724500025251,"user_tz":-60,"elapsed":4,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AAQKpHGou7QW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fine_tune_results = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n","ft_stock_model = fine_tune_results.fine_tuned_model\n","ft_stock_model"],"metadata":{"id":"gwzQvvEPsiAI","executionInfo":{"status":"ok","timestamp":1724500033327,"user_tz":-60,"elapsed":300,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response=client.fine_tuning.jobs.list_events(fine_tuning_job_id)\n","events=response.data\n","events.reverse()\n","\n","for event in events:\n","  print(event)"],"metadata":{"id":"WYA2HUhJHbJz","executionInfo":{"status":"ok","timestamp":1724500029945,"user_tz":-60,"elapsed":450,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["steps=[]\n","train_loss=[]\n","for e in events:\n","  if(e.data):\n","    steps.append(e.data['step'])\n","    train_loss.append(e.data['train_loss'])\n","print(steps)\n","print(train_loss)"],"metadata":{"id":"RLsxE6QnsI39","executionInfo":{"status":"ok","timestamp":1724500037666,"user_tz":-60,"elapsed":287,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(steps,train_loss,marker='o',linestyle='-')"],"metadata":{"id":"0WmctOzAHjCJ","executionInfo":{"status":"ok","timestamp":1724500042961,"user_tz":-60,"elapsed":257,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n","fine_tuned_model_id = response.fine_tuned_model\n","\n","if fine_tuned_model_id is None:\n","    raise RuntimeError(\"Fine-tuned model ID not found. Your job has likely not been completed yet.\")\n","\n","print(\"Fine-tuned model ID:\", fine_tuned_model_id)"],"metadata":{"id":"68ILhdmHHjGt","executionInfo":{"status":"ok","timestamp":1724500051137,"user_tz":-60,"elapsed":279,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GjhVmiYrOFW-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["system_message=\"You are a helpful stock market price prediction assistant. You have to predict the completion value for the given stock data\""],"metadata":{"id":"0zJs5-xhJUc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!head -n 5 google_stock_validation_prepared.jsonl"],"metadata":{"id":"tF0DOW2TJyOq","executionInfo":{"status":"ok","timestamp":1724500056797,"user_tz":-60,"elapsed":275,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test = pd.read_json('google_stock_validation_prepared.jsonl', lines=True)\n","test.head()"],"metadata":{"id":"ms4rj5pBPw8b","executionInfo":{"status":"ok","timestamp":1724500061383,"user_tz":-60,"elapsed":275,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test['prompt'][0]"],"metadata":{"id":"kn-frDv3P1cU","executionInfo":{"status":"ok","timestamp":1724500066235,"user_tz":-60,"elapsed":301,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We need to use the same separator following the prompt which we used during fine-tuning. In this case it is\n","\n","Based on the analysis we will perform the following actions:\n","- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n","- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: Y\n","\n","Since we're concerned with classification, we want the temperature to be as low as possible, and we only require one token completion to determine the prediction of the model.\n","\n"],"metadata":{"id":"uMrpSmiJQDok"}},{"cell_type":"code","source":["fine_tune_job = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n"],"metadata":{"id":"I7TrzPOPP1fR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ft_model = fine_tune_job.fine_tuned_model\n","# note that this calls the legacy completions api - https://platform.openai.com/docs/api-reference/completions\n","\n","res=client.completions.create(\n","    model=ft_model,\n","    prompt=test['prompt'][0]+\"  ->  \",\n","    max_tokens=1,\n","    temperature=0,\n","\n","\n",")\n","res.choices[0].text"],"metadata":{"id":"mxRK5u07P1iv","executionInfo":{"status":"ok","timestamp":1724500086520,"user_tz":-60,"elapsed":259,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(res)"],"metadata":{"id":"mLvFDQRbQt5b","executionInfo":{"status":"ok","timestamp":1724500091285,"user_tz":-60,"elapsed":283,"user":{"displayName":"RAHUL KUMAR","userId":"04858592732229532104"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0cMHcTkFP1my"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"HJLJ2KL8Dx85"}}]}